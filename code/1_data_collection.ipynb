{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Collect Annual Data from PubMed Website and Save each Files in the Same Folder"
      ],
      "metadata": {
        "id": "e-YvpfpQzWns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n-9qfnfx35S"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def extract_text(element, tag):\n",
        "    try:\n",
        "        return element.find(tag).text\n",
        "    except AttributeError:\n",
        "        return None\n",
        "\n",
        "def extract_date(pub_date):\n",
        "    try:\n",
        "        year = pub_date.find('Year').text\n",
        "        month = pub_date.find('Month').text\n",
        "        return f\"{year}-{month}\"\n",
        "    except AttributeError:\n",
        "        return None\n",
        "\n",
        "def parse_mesh_headings(mesh_list):\n",
        "    if mesh_list is None:\n",
        "        return None\n",
        "    headings = [mh.find('DescriptorName').text for mh in mesh_list.findall('MeshHeading') if mh.find('DescriptorName') is not None]\n",
        "    return '; '.join(headings) if headings else None\n",
        "\n",
        "def parse_keywords(keyword_list):\n",
        "    if keyword_list is None:\n",
        "        return None\n",
        "    keywords = [kw.text for kw in keyword_list.findall('Keyword') if kw.text is not None]\n",
        "    return '; '.join(keywords) if keywords else None\n",
        "\n",
        "def parse_xml(file_path):\n",
        "    try:\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error parsing {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for article in root.findall('PubmedArticle'):\n",
        "        date_element = article.find('.//PubDate')\n",
        "        title_element = article.find('.//ArticleTitle')\n",
        "        abstract_element = article.find('.//Abstract/AbstractText')\n",
        "        mesh_list_element = article.find('.//MeshHeadingList')\n",
        "        keyword_list_element = article.find('.//KeywordList')\n",
        "\n",
        "        date = extract_date(date_element)\n",
        "        title = title_element.text if title_element is not None else None\n",
        "        abstract = abstract_element.text if abstract_element is not None else None\n",
        "        mesh_headings = parse_mesh_headings(mesh_list_element)\n",
        "        keywords = parse_keywords(keyword_list_element)\n",
        "\n",
        "        records.append({\n",
        "            'Date': date,\n",
        "            'Title': title,\n",
        "            'Abstract': abstract,\n",
        "            'MeshHeading': mesh_headings,\n",
        "            'Keywords': keywords\n",
        "        })\n",
        "\n",
        "    return records\n",
        "\n",
        "def save_records_to_csv(records, output_file):\n",
        "    df = pd.DataFrame(records)\n",
        "    if not os.path.isfile(output_file):\n",
        "        df.to_csv(output_file, index=False)\n",
        "    else:\n",
        "        df.to_csv(output_file, mode='a', header=False, index=False)\n",
        "    print(f\"Data successfully saved to {output_file}\")\n",
        "\n",
        "def process_directory(directory_path, output_csv_file, start_number=None):\n",
        "    all_records = []\n",
        "    error_log = []\n",
        "    start_processing = False if start_number else True\n",
        "\n",
        "    for filename in sorted(os.listdir(directory_path)):\n",
        "        if filename.endswith('.xml'):\n",
        "            # Check if we should start processing based on start_number\n",
        "            if not start_processing and filename.startswith(f'pubmed24n{start_number:04d}'):\n",
        "                start_processing = True\n",
        "\n",
        "            if start_processing:\n",
        "                file_path = os.path.join(directory_path, filename)\n",
        "                print(f\"Processing file: {file_path}\")\n",
        "                try:\n",
        "                    records = parse_xml(file_path)\n",
        "                    if records:\n",
        "                        save_records_to_csv(records, output_csv_file)  # Save after processing each file\n",
        "                except Exception as e:\n",
        "                    error_message = f\"Error processing {file_path}: {e}\"\n",
        "                    print(error_message)\n",
        "                    error_log.append(error_message)\n",
        "\n",
        "    if error_log:\n",
        "        error_log_file = os.path.join(directory_path, 'error_log.txt')\n",
        "        with open(error_log_file, 'w') as f:\n",
        "            for error in error_log:\n",
        "                f.write(error + \"\\n\")\n",
        "        print(f\"Error log saved to {error_log_file}\")\n",
        "\n",
        "# Example usage\n",
        "directory_path = os.path.dirname(os.path.abspath(__file__))\n",
        "output_csv_file = os.path.join(directory_path, 'output_file.csv')\n",
        "start_number = 0 # Change this to the number you want to start from\n",
        "\n",
        "# Process all XML files in the directory and save to a CSV file\n",
        "process_directory(directory_path, output_csv_file, start_number)"
      ]
    }
  ]
}